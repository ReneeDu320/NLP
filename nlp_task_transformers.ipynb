{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NLP use case\n",
    "\n",
    "- Classifying whole sentences\n",
    "- Classifying each word in a sentence (Named Entity Recognition)\n",
    "- Answering a question given a context\n",
    "- Text summarization\n",
    "- Fill in the blanks\n",
    "- Translating from one language to another"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "!pip install transformers[sentencepiece]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import pipeline\n",
    "import textwrap\n",
    "wrapper = textwrap.TextWrapper(width=80, break_long_words=False, break_on_hyphens=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## classifying whole sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fcd6da1b2a7c472086a6a559861d77c6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/629 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dedd7515fab44c2c8364d2544f33a67b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/255M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f4edfa9ef1574957a1100ed8aa0becbc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/48.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0d54b98229014fdc80951a72d2cec7c0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/226k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Sentence:\n",
      "The flights were on time both in Sydney and the connecting flight in Singapore.\n",
      "The organisation to cope with the COVID 19 restrictions while in transit was\n",
      "well planned and directions easy to follow, the plane was comfortable with a\n",
      "reasonable selection of in flight entertainment. Crew were pleasant and helpful.\n",
      "\n",
      "This sentence is classified with a POSITIVE sentiment\n"
     ]
    }
   ],
   "source": [
    "sentence = 'The flights were on time both in Sydney and the connecting flight in Singapore. The organisation to cope with the COVID 19 restrictions while in transit was well planned and directions easy to follow, the plane was comfortable with a reasonable selection of in flight entertainment. Crew were pleasant and helpful.'\n",
    "classifier = pipeline('text-classification', model='distilbert-base-uncased-finetuned-sst-2-english')\n",
    "c = classifier(sentence)\n",
    "print('\\nSentence:')\n",
    "print(wrapper.fill(sentence))\n",
    "print(f\"\\nThis sentence is classified with a {c[0]['label']} sentiment\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classifying each word in a sentence (Named Entity Recognition)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence = \"Singapore Airlines was the first airline to fly the A380. Chew Choon Seng was Singapore Airline's CEO at the time. Singapore Airlines flies to New York daily.\"\n",
    "ner = pipeline('token-classification', model='dbmdz/bert-large-cased-finetuned-conll03-english', grouped_entities=True)\n",
    "ners = ner(sentence)\n",
    "print('\\nSentence:')\n",
    "print(wrapper.fill(sentence))\n",
    "print('\\n')\n",
    "for n in ners:\n",
    "  print(f\"{n['word']} -> {n['entity_group']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Answering a question given a context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "context = '''\n",
    "Singapore Airlines was founded in 1947 and was originally known as Malayan Airways. It is the national airline of Singapore and is based at Singapore Changi Airport. \n",
    "From this hub, the airline flies to more than 60 destinations, with flights to Seoul, Tokyo and Melbourne among the most popular of its routes. \n",
    "It is particularly strong in Southeast Asian and Australian destinations (the so-called Kangaroo Route), but also flies to 6 different continents, covering 35 countries.\n",
    "There are more than 100 planes in the Singapore Airlines fleet, most of which are Airbus aircraft plus a smaller amount of Boeings.\n",
    "The company is known for frequently updating the aircraft in its fleet.'''\n",
    "\n",
    "\n",
    "question = 'How many aircrafts does Singapore Airlines have?'\n",
    "\n",
    "print('Text:')\n",
    "print(wrapper.fill(context))\n",
    "print('\\nQuestion:')\n",
    "print(question)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "qa = pipeline('question-answering', model='distilbert-base-cased-distilled-squad')\n",
    "\n",
    "print('\\nQuestion:')\n",
    "print(question + '\\n')\n",
    "print('Answer:')\n",
    "a = qa(context=context, question=question)\n",
    "a['answer']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Text summarization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "review = '''\n",
    "Extremely unusual time to fly as we needed an exemption to fly out of Australia from the government. We obtained one as working in Tokyo for the year as teachers.\n",
    "The check in procedure does take a lot longer as more paperwork and phone calls are needed to check if you are allowed to travel. The staff were excellent in explaining the procedure as they are working with very few numbers.\n",
    "The flight had 40 people only, so lots of room and yes we had 3 seats each. The service of meals and beverages was done very quickly and efficiently.\n",
    "Changi airport was like a ghost town with most shops closed and all passengers are walked/transported to a transit zone until your next flight is ready. You are then walked in single file or transported to your next flight, so very strange as at times their seemed be more workers in PPE gear than passengers.\n",
    "The steps we went through at Narita were extensive, downloading apps, fill in paperwork and giving a saliva sample to test for covid 19. \n",
    "It took about 2 hours to get through the steps and we only sat down for maybe 10 minutes at the last stop to get back your covid results. \n",
    "The people involved were fantastic and we were lucky that we were numbers two and three in the initial first line up, but still over 2 hours it took so be aware. We knew we were quick as the people picking us up told us we were first out.'''\n",
    "\n",
    "print('\\nOriginal text:\\n')\n",
    "print(wrapper.fill(review))\n",
    "summarize = pipeline('summarization', model='sshleifer/distilbart-cnn-12-6')\n",
    "summarized_text = summarize(review)[0]['summary_text']\n",
    "print('\\nSummarized text:')\n",
    "print(wrapper.fill(summarized_text))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fill in the blanks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bd091d37f9b64e5cabe89440fe012e0b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/480 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "299e2946efcf4a47a53c8d973f974f8b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/316M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0825d830621242ed9ac55820fb4f7bba",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/878k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d733d40dffd842c7a2d4fb99bc07634c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/446k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "212827949525481d8153a2e2bf25f007",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/1.29M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "It is the national anthem of Singapore\n",
      "It is the national capital of Singapore\n",
      "It is the national pride of Singapore\n",
      "It is the national treasure of Singapore\n",
      "It is the national motto of Singapore\n"
     ]
    }
   ],
   "source": [
    "sentence = 'It is the national <mask> of Singapore'\n",
    "mask = pipeline('fill-mask', model='distilroberta-base')\n",
    "masks = mask(sentence)\n",
    "for m in masks:\n",
    "  print(m['sequence'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Singapore Airlines is the national airline of Singapore\n",
      "Singapore Airlines is the national carrier of Singapore\n",
      "Singapore Airlines is the national airport of Singapore\n",
      "Singapore Airlines is the national airlines of Singapore\n",
      "Singapore Airlines is the national capital of Singapore\n"
     ]
    }
   ],
   "source": [
    "sentence = 'Singapore Airlines is the national <mask> of Singapore'\n",
    "mask = pipeline('fill-mask', model='distilroberta-base')\n",
    "masks = mask(sentence)\n",
    "for m in masks:\n",
    "  print(m['sequence'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Translation (English to German)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "english = '''Singapore Airlines is my favourite airline'''\n",
    "\n",
    "translator = pipeline('translation_en_to_de', model='t5-base')\n",
    "german = translator(english)\n",
    "print('\\nEnglish:')\n",
    "print(english)\n",
    "print('\\nGerman:')\n",
    "print(german[0]['translation_text'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## bias in bert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e7b028afd0814ba88d80e6590d60c2c2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/570 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "41e8b75763584af69117320ab3cb1cbf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/420M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForMaskedLM: ['cls.seq_relationship.weight', 'cls.seq_relationship.bias']\n",
      "- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cd933722df164835a849f0679b4ed39a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/28.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fd630905a4c74781902dac48bae70a2d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/226k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9387c0e03ecd467489b7d2e3ca4d92b6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/455k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[{'score': 0.9641985893249512,\n",
       "  'token': 2016,\n",
       "  'token_str': 'she',\n",
       "  'sequence': \"the nurse needed a drink because she was tired after a long day's work at the hospital.\"},\n",
       " {'score': 0.022492405027151108,\n",
       "  'token': 2002,\n",
       "  'token_str': 'he',\n",
       "  'sequence': \"the nurse needed a drink because he was tired after a long day's work at the hospital.\"},\n",
       " {'score': 0.001403257017955184,\n",
       "  'token': 1045,\n",
       "  'token_str': 'i',\n",
       "  'sequence': \"the nurse needed a drink because i was tired after a long day's work at the hospital.\"},\n",
       " {'score': 0.001286151586100459,\n",
       "  'token': 2009,\n",
       "  'token_str': 'it',\n",
       "  'sequence': \"the nurse needed a drink because it was tired after a long day's work at the hospital.\"},\n",
       " {'score': 0.0006937936414033175,\n",
       "  'token': 3071,\n",
       "  'token_str': 'everyone',\n",
       "  'sequence': \"the nurse needed a drink because everyone was tired after a long day's work at the hospital.\"}]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "fill_mask = pipeline(\"fill-mask\", model=\"bert-base-uncased\")\n",
    "results = fill_mask(\"The nurse needed a drink because [MASK] was tired after a long day's work at the hospital.\")\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'score': 0.9312540292739868,\n",
       "  'token': 2002,\n",
       "  'token_str': 'he',\n",
       "  'sequence': \"the doctor needed a drink because he was tired after a long day's work at the hospital.\"},\n",
       " {'score': 0.0449102483689785,\n",
       "  'token': 2016,\n",
       "  'token_str': 'she',\n",
       "  'sequence': \"the doctor needed a drink because she was tired after a long day's work at the hospital.\"},\n",
       " {'score': 0.002265271497890353,\n",
       "  'token': 1045,\n",
       "  'token_str': 'i',\n",
       "  'sequence': \"the doctor needed a drink because i was tired after a long day's work at the hospital.\"},\n",
       " {'score': 0.0021235239692032337,\n",
       "  'token': 2009,\n",
       "  'token_str': 'it',\n",
       "  'sequence': \"the doctor needed a drink because it was tired after a long day's work at the hospital.\"},\n",
       " {'score': 0.0010061485227197409,\n",
       "  'token': 3071,\n",
       "  'token_str': 'everyone',\n",
       "  'sequence': \"the doctor needed a drink because everyone was tired after a long day's work at the hospital.\"}]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results = fill_mask(\"The doctor needed a drink because [MASK] was tired after a long day's work at the hospital.\")\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'score': 0.8818804025650024,\n",
       "  'token': 2016,\n",
       "  'token_str': 'she',\n",
       "  'sequence': 'we had a meeting with our company receptionist and she was not happy.'},\n",
       " {'score': 0.02969827875494957,\n",
       "  'token': 1045,\n",
       "  'token_str': 'i',\n",
       "  'sequence': 'we had a meeting with our company receptionist and i was not happy.'},\n",
       " {'score': 0.016220834106206894,\n",
       "  'token': 2002,\n",
       "  'token_str': 'he',\n",
       "  'sequence': 'we had a meeting with our company receptionist and he was not happy.'},\n",
       " {'score': 0.008252743631601334,\n",
       "  'token': 3071,\n",
       "  'token_str': 'everyone',\n",
       "  'sequence': 'we had a meeting with our company receptionist and everyone was not happy.'},\n",
       " {'score': 0.002857781480997801,\n",
       "  'token': 2009,\n",
       "  'token_str': 'it',\n",
       "  'sequence': 'we had a meeting with our company receptionist and it was not happy.'}]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results = fill_mask(\"We had a meeting with our company receptionist and [MASK] was not happy.\")\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'score': 0.9263392686843872,\n",
       "  'token': 2002,\n",
       "  'token_str': 'he',\n",
       "  'sequence': 'we had a meeting with our company president and he was not happy.'},\n",
       " {'score': 0.056357014924287796,\n",
       "  'token': 2016,\n",
       "  'token_str': 'she',\n",
       "  'sequence': 'we had a meeting with our company president and she was not happy.'},\n",
       " {'score': 0.003176403697580099,\n",
       "  'token': 1045,\n",
       "  'token_str': 'i',\n",
       "  'sequence': 'we had a meeting with our company president and i was not happy.'},\n",
       " {'score': 0.0009640384814701974,\n",
       "  'token': 2009,\n",
       "  'token_str': 'it',\n",
       "  'sequence': 'we had a meeting with our company president and it was not happy.'},\n",
       " {'score': 0.0006586540257558227,\n",
       "  'token': 3071,\n",
       "  'token_str': 'everyone',\n",
       "  'sequence': 'we had a meeting with our company president and everyone was not happy.'}]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results = fill_mask(\"We had a meeting with our company president and [MASK] was not happy.\")\n",
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## IMDB dataset test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading and preparing dataset imdb/plain_text (download: 80.23 MiB, generated: 127.02 MiB, post-processed: Unknown size, total: 207.25 MiB) to /Users/karen/.cache/huggingface/datasets/imdb/plain_text/1.0.0/2fdd8b9bcadd6e7055e742a706876ba43f19faee861df134affd7a3f60fc38a1...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7f5114af590741c8825da6a864e48196",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data:   0%|          | 0.00/84.1M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "55b26aba114847e89457dc90eba2871c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split:   0%|          | 0/25000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "db619c315747458aa89f667736da80e0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating test split:   0%|          | 0/25000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "17ae3c5b05224a4bba71e50eebb4ebbf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating unsupervised split:   0%|          | 0/50000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset imdb downloaded and prepared to /Users/karen/.cache/huggingface/datasets/imdb/plain_text/1.0.0/2fdd8b9bcadd6e7055e742a706876ba43f19faee861df134affd7a3f60fc38a1. Subsequent calls will reuse this data.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aa068552366e48b28e9c76260a58817a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['text', 'label'],\n",
       "        num_rows: 25000\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['text', 'label'],\n",
       "        num_rows: 25000\n",
       "    })\n",
       "    unsupervised: Dataset({\n",
       "        features: ['text', 'label'],\n",
       "        num_rows: 50000\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "imdb = load_dataset(\"imdb\")\n",
    "imdb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'text': 'I rented I AM CURIOUS-YELLOW from my video store because of all the controversy that surrounded it when it was first released in 1967. I also heard that at first it was seized by U.S. customs if it ever tried to enter this country, therefore being a fan of films considered \"controversial\" I really had to see this for myself.<br /><br />The plot is centered around a young Swedish drama student named Lena who wants to learn everything she can about life. In particular she wants to focus her attentions to making some sort of documentary on what the average Swede thought about certain political issues such as the Vietnam War and race issues in the United States. In between asking politicians and ordinary denizens of Stockholm about their opinions on politics, she has sex with her drama teacher, classmates, and married men.<br /><br />What kills me about I AM CURIOUS-YELLOW is that 40 years ago, this was considered pornographic. Really, the sex and nudity scenes are few and far between, even then it\\'s not shot like some cheaply made porno. While my countrymen mind find it shocking, in reality sex and nudity are a major staple in Swedish cinema. Even Ingmar Bergman, arguably their answer to good old boy John Ford, had sex scenes in his films.<br /><br />I do commend the filmmakers for the fact that any sex shown in the film is shown for artistic purposes rather than just to shock people and make money to be shown in pornographic theaters in America. I AM CURIOUS-YELLOW is a good film for anyone wanting to study the meat and potatoes (no pun intended) of Swedish cinema. But really, this film doesn\\'t have much of a plot.',\n",
       " 'label': 0}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#print one example\n",
    "imdb['train'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['text', 'label'],\n",
       "        num_rows: 1600\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['text', 'label'],\n",
       "        num_rows: 25000\n",
       "    })\n",
       "    unsupervised: Dataset({\n",
       "        features: ['text', 'label'],\n",
       "        num_rows: 50000\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['text', 'label'],\n",
       "        num_rows: 400\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "imdb['train'] = imdb['train'].shuffle(seed=1).select(range(2000))\n",
    "imdb['train']\n",
    "\n",
    "imdb_train_validation = imdb['train'].train_test_split(train_size=0.8)\n",
    "\n",
    "imdb_train_validation['validation'] = imdb_train_validation.pop('test')\n",
    "\n",
    "imdb.update(imdb_train_validation)\n",
    "imdb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'text': ['This is just a precious little diamond. The play, the script are excellent. I cant compare this movie with anything else, maybe except the movie \"Leon\" wonderfully played by Jean Reno and Natalie Portman. But... What can I say about this one? This is the best movie Anne Parillaud has ever played in (See please \"Frankie Starlight\", she\\'s speaking English there) to see what I mean. The story of young punk girl Nikita, taken into the depraved world of the secret government forces has been exceptionally over used by Americans. Never mind the \"Point of no return\" and especially the \"La femme Nikita\" TV series. They cannot compare the original believe me! Trash these videos. Buy this one, do not rent it, BUY it. BTW beware of the subtitles of the LA company which \"translate\" the US release. What a disgrace! If you cant understand French, get a dubbed version. But you\\'ll regret later :)',\n",
       "  'When I say this is my favourite film of all time, that comment is not to be taken lightly. I probably watch far too many films than is healthy for me, and have loved quite a few of them. I first saw \"La Femme Nikita\" nearly ten years ago, and it still manages to be my absolute favourite. Why?<br /><br />This is more than an incredibly stylish and sexy thriller. Luc Besson\\'s great flair for impeccable direction, fashion, and appropriate usage of music makes this a very watchable film. But it is Anne Parillaud\\'s perfect rendering of a complex character who transforms from a heartless killer into a compassionate, vibrant young woman that makes this film beautiful. I can\\'t keep my eyes off of her when she is on screen.<br /><br />I have seen several of Luc Besson\\'s films including \"Subway\", \"The Professional\", and the irritating \"Fifth Element\", and \"Nikita\" is without a doubt, far superior to any of these. Although this film has tragic elements, it is ultimately extremely hopeful. It is the story of a person who is cruel and merciless, who ultimately comes to realize her own humanity and her own personal power. That, to me is extremely inspiring. If there is hope for Nikita, there is hope for all of us.',\n",
       "  'I saw this movie because I am a huge fan of the TV series of the same name starring Roy Dupuis and Pet Wilson. The movie was really good and I saw how the TV show is based on the movie. A few episodes of the TV series came directly from the movie and their similarity was amazing. To keep things short, any fan of the movie has to watch the series and any fan of the series must see the original Nikita.'],\n",
       " 'label': [-1, -1, -1]}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "imdb['test'] = imdb['test'].shuffle(seed=1).select(range(400))\n",
    "imdb['unsupervised'][:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['text', 'label'],\n",
       "        num_rows: 1600\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['text', 'label'],\n",
       "        num_rows: 400\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['text', 'label'],\n",
       "        num_rows: 400\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#remove the unsupervised part\n",
    "imdb.pop('unsupervised')\n",
    "imdb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## overview of the new IMDB dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>75</th>\n",
       "      <td>I pulled down a VHS box from my vast collection - many unseen - and picked out a movie, based on the box art, I thought would be fun, and yes, bad. Prison had that 80s cheesy look all over that box. I sat down and watched, and lo! and behold!, fo...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1284</th>\n",
       "      <td>You cannot deny that we have an affinity for speed. That's why movies like Fast and the Furious, Dhoom, Rempit get made to play to the satisfaction of audiences, especially local ones. We live on a tiny island, and I cannot fathom why, for the re...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>408</th>\n",
       "      <td>Admittedly, I didn't have high expectations of \"Corky Romano.\" But then again, who did? However, I felt it deserved the benefit of the doubt. I had no high hopes of \"Joe Dirt\" either--another recent comedy starring an SNL cast member--and I ended...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1282</th>\n",
       "      <td>Given how corny these movies are, you gotta figure that they must have had fun making them. The movie focuses on a house that strangely accommodates whomever lives there. The inhabitants were: author Charles Hillyer (Denholm Elliott (with hair!))...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1447</th>\n",
       "      <td>Really. Does any week go by that Oprah doesn't remind us that she was abused as child?&lt;br /&gt;&lt;br /&gt;She makes herself the focus of every interview.&lt;br /&gt;&lt;br /&gt;Oprah cannot resist commenting on the answer to every question she asks. She often interr...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1144</th>\n",
       "      <td>I have absolutely no knowledge of author Phillipa Pearce or any of her novels and if TOM`S MIDNIGHT GARDEN is typical of her work I probably would have had little interest in her books as a child . When I was a child I wasn`t really interested in...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1381</th>\n",
       "      <td>This film can not even be said to be bad for it is sadly, just painfully mediocre. Lacking any real wit or imagination, a thin plot is stretched to the absolute limit and the `jokes' (which are predictable and threadbare) are spun out to such ino...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>181</th>\n",
       "      <td>If you really want to know how most of the actors and directors in the Hollywood scene \"made it\" to where they are, the vast majority will tell you (assuming they will tell) that a strange coincidence took place. They happened to meet the right p...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1183</th>\n",
       "      <td>Oh man, what was Sam Mraovich thinking? What was anyone who was involved in this \"film\" thinking? Mraovich is the head of nearly everything of \"Ben and Arthur\": Director, writer, producer (also EXECUTIVE producer!), caster, lead star- you name it...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1103</th>\n",
       "      <td>I can't believe it that was the worst movie i have ever seen in my life. i laughed a couple of times. ( probably because of how stupid it was ) If someone paid me to see that movie again i wouldn't. the plot was so horrible , it made no sense , a...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                                                                                                                                                           text  \\\n",
       "75    I pulled down a VHS box from my vast collection - many unseen - and picked out a movie, based on the box art, I thought would be fun, and yes, bad. Prison had that 80s cheesy look all over that box. I sat down and watched, and lo! and behold!, fo...   \n",
       "1284  You cannot deny that we have an affinity for speed. That's why movies like Fast and the Furious, Dhoom, Rempit get made to play to the satisfaction of audiences, especially local ones. We live on a tiny island, and I cannot fathom why, for the re...   \n",
       "408   Admittedly, I didn't have high expectations of \"Corky Romano.\" But then again, who did? However, I felt it deserved the benefit of the doubt. I had no high hopes of \"Joe Dirt\" either--another recent comedy starring an SNL cast member--and I ended...   \n",
       "1282  Given how corny these movies are, you gotta figure that they must have had fun making them. The movie focuses on a house that strangely accommodates whomever lives there. The inhabitants were: author Charles Hillyer (Denholm Elliott (with hair!))...   \n",
       "1447  Really. Does any week go by that Oprah doesn't remind us that she was abused as child?<br /><br />She makes herself the focus of every interview.<br /><br />Oprah cannot resist commenting on the answer to every question she asks. She often interr...   \n",
       "1144  I have absolutely no knowledge of author Phillipa Pearce or any of her novels and if TOM`S MIDNIGHT GARDEN is typical of her work I probably would have had little interest in her books as a child . When I was a child I wasn`t really interested in...   \n",
       "1381  This film can not even be said to be bad for it is sadly, just painfully mediocre. Lacking any real wit or imagination, a thin plot is stretched to the absolute limit and the `jokes' (which are predictable and threadbare) are spun out to such ino...   \n",
       "181   If you really want to know how most of the actors and directors in the Hollywood scene \"made it\" to where they are, the vast majority will tell you (assuming they will tell) that a strange coincidence took place. They happened to meet the right p...   \n",
       "1183  Oh man, what was Sam Mraovich thinking? What was anyone who was involved in this \"film\" thinking? Mraovich is the head of nearly everything of \"Ben and Arthur\": Director, writer, producer (also EXECUTIVE producer!), caster, lead star- you name it...   \n",
       "1103  I can't believe it that was the worst movie i have ever seen in my life. i laughed a couple of times. ( probably because of how stupid it was ) If someone paid me to see that movie again i wouldn't. the plot was so horrible , it made no sense , a...   \n",
       "\n",
       "      label  \n",
       "75        1  \n",
       "1284      0  \n",
       "408       0  \n",
       "1282      1  \n",
       "1447      0  \n",
       "1144      0  \n",
       "1381      0  \n",
       "181       1  \n",
       "1183      0  \n",
       "1103      0  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "pd.set_option('max_colwidth', 250)\n",
    "\n",
    "imdb.set_format('pandas')\n",
    "df = imdb['train'][:]\n",
    "df.sample(frac=1 ,random_state=1).head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Despite positive reviews and screenings at the international festivals, this movie is not for everyone.The story is very similar to other movies, in which a teenage girl from the family of immigrants needs to overcome many common personal problems of her age, and also to struggle against the pressure of ethnic traditions in her family. She does that by choosing some kind of sport, and with the help of a local boy, that for some reason falls in love with her, she confronts her problems and wins.In Girlfight it\\'s boxing, in Bend it like Beckham it\\'s soccer, and now it\\'s Kung Fu.But Fighter is much inferior product than these two, it was simply embarrassing to watch it. Semra Turan, the \"actress\" that playing the role of a teenage girl, maybe can do a lot of things, but one thing she can\\'t do is to act. Her presence on the screen is anemic and clumsy, the dramatic situations, in which she tries to show some emotions, are dreadful, her body and facial language are of amateur actress, badly instructed by the director. The rest of the cast is a little better, but they just cannot save this cliché movie with stereotypical characters and shallow plot. Besides a few relatively good moments this movie has nothing new or interesting to offer.Even the kung fu fighting is not a reason to watch this, it\\'s just so boring. The slow motion was really unnecessary, the choreography was basic and lacked the inspiration, and most of the kung fu scenes are just training or standing in all kind of kung fu positions, not actually fighting. Not to mention how ridiculous it looks when a small and skinny girl fights big and muscular boys, and knocks them off their feet. The only reason this movie has been noticed at all is because it\\'s European. It\\'s very easy to publicize this movie - A first martial arts film from Denmark, but don\\'t be fooled, it\\'s not. It\\'s just a drama about stupid teenage girl and her problems, which are, by the way, not really convincing.Bad movie with embarrassing lines, acting and story.'"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#replace special chars\n",
    "df['text'] = df.text.str.replace('<br />', '')\n",
    "df.loc[0, 'text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYIAAAEHCAYAAACjh0HiAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/YYfK9AAAACXBIWXMAAAsTAAALEwEAmpwYAAARK0lEQVR4nO3df5BdZ13H8ffHtLSVX03otrRJJB2JjilCYZaAFBEoY8MPTXWsk6IYxkJhps7gyIw0jA52NID84QhiRyq/otDWiGIjo0KMNAVb226xAmnoJFLaxNRmIekUUQoNX/+4p9PbdH/cZO/+yD7v18zOOec5z3n2u5ub+7nnOffuSVUhSWrXD813AZKk+WUQSFLjDAJJapxBIEmNMwgkqXEGgSQ1ziDQopTk95J8Yr7rmE1J/jHJxvmuQyc+g0BzIsmmJP9wVNueSdo2zG11J6aqenVVbZnvOnTiMwg0V24CLkiyBCDJM4GTgRcc1fbsru/Akpw05FpnbJCaFmLdapNBoLlyO70n/vO77ZcBnwfuPqrtP6vqQJJzkmxLcijJ3iRvfnSgbtrnU0k+keQh4I1Jzk2yM8m3k2wHzujrf2rX91tJHkxye5KzJioyyTe6s5e7khxO8rEkp/btf12SO7txbk7y3KOOfUeSLwPfmeiJPkkluSLJHmDPVGMmuTLJp446/v1JPtCt35jkTX37fj3J7q7uzyZ5Vtd+VZI/6dZPTvKdJO/rtk9L8t0kSyf7h9PiZxBoTlTV94Bb6T3Z0y2/AHzxqLZHzwauA/YD5wC/BLw7yYV9Q64HPgWcDnwSuBa4g14A/D7QP3e+EXg6sBJ4BvBW4P+mKPdXgIuAHwV+DPgdgCQvAD4KvKUb50PAtiSn9B17KfBa4PSqemSS8S8GXgSsmWbM64DXJHla9/2XAL/c/ayPk+Ri4J3ALwIj9H6313W7dwIv79ZfCPw38DPd9k8Bd1fV4Sl+H1rkDALNpZ089qT/0/SerL5wVNvOJCuBlwLvqKrvVtWdwIeBN/SNdUtV/V1V/YDeE98Lgd+tqoer6ibg7/v6fp/ek+yzq+pIVd1RVQ9NUecHq2pfVR0CNtN7cgd4M/Chqrq1G2cL8DDw4r5jP9AdO1XQvKeqDnV9Jh2zqu4FvkQvOABeCfxvVf3bBGO+pRt3dxdA7wbO784KbgFWJ3kGvd/1R4DlSZ5CLxB2TlGrGmAQaC7dBLy0m4YYqao9wM3AS7q253R9zgEOVdW3+469F1jet72vb/0c4HBVfeeo/o/6S+CzwPVJDiR5X5KTp6izf+x7u/EBngW8vZvCeTDJg/TOMs6Z5NhBxp9uzGt5LIhezwRnA33jvL9vjENAgOVd4IzRe9J/Gb0n/puBCzAIhEGguXULvSmay4F/BehemR/o2g5U1T3d9rIkT+079keA/+rb7v+zufcDS5M8+aj+dN/j+1V1VVWtAV4CvA74tSnqXHnUOAe69X3A5qo6ve/rh6vqur7+g/w53/4+043518DLk6wAfoHJg2Af8Jajxjmtqm7u9u+kd0bxfHrXa3bSm/5ayzFenNfiYxBozvS9Mv0telNCj/pi13ZT128fvVes7+ku9D4XuIzetYCJxr23G/eqJE9K8lLg5x7dn+QVSX6ym2N/iN5U0ZEpSr0iyYoky+jNu/9V1/7nwFuTvCg9T07y2qMC61hNOWZVjQM3Ah8D7qmq3ZOM82fApiTndT/z05Nc0rd/J73wu6u7XnMj8KZuzPEZ1K9FwCDQXNsJnEnvyf9RX+ja+l+ZXgqsovdq/NPAu6pq+xTjvp7eBdhDwLuAv+jb90x6F5YfAnZ3NUz1YbNrgc8BX+++/gCgqsbozel/EDgM7AXeOMU40xpwzGuBVzH52QBV9WngD+lNfz0EfBV4dV+Xm4HTeOx3fBfwXTwbEBBvTCM9Jsk3gDdV1T/Pdy3SXPGMQJIaZxBIUuOcGpKkxnlGIEmNMwgkqXEL4q8fnnHGGbVq1ar5LkOSFq077rjjm1U1MtG+BREEq1atYmxsbL7LkKRFK8m9k+1zakiSGmcQSFLjDAJJapxBIEmNMwgkqXEGgSQ1bqAg6G7K/ZXuBttjXduyJNuT7OmWS/v6b0rvhuN3J7lotoqXJM3csZwRvKKqzq+q0W77SmBHVa0GdnTbJFkDbADOA9YBV3c3BJEkLUAzmRpaD2zp1rfw2A221wPXdzcRv4fejTbWzuD7aBpJjutLmi8+ZheWQYOggM8luSPJ5V3bWVV1P0C3PLNrX87jb869n8ffdByAJJcnGUsyNj7unfJmoqom/ZpqvzRffMwuLIP+iYkLqupAkjOB7Um+NkXfiWL7Cf+CVXUNcA3A6Oio/8KSNE8GOiOoqgPd8iC9+8euBR5IcjZAtzzYdd8PrOw7fAW9+85KkhagaYMgyZOTPPXRdeBn6d0Yexuwseu2EbihW98GbEhySpJzgdXAbcMuXJI0HINMDZ0FfLq7UHMScG1V/VOS24GtSS4D7gMuAaiqXUm2AncBjwBXVNWRWalekjRj0wZBVX0deN4E7d8CLpzkmM3A5hlXJ0madX6yWJIaZxBIUuMMAklqnEEgSY0zCCSpcQaBJDXOIJCkxhkEktQ4g0CSGmcQSFLjDAJJapxBIEmNMwgkqXEGgSQ1ziCQpMYZBJLUOINAkhpnEEhS4wwCSWqcQSBJjTMIJKlxBoEkNc4gkKTGGQSS1DiDQJIaZxBIUuMMAklqnEEgSY0zCCSpcQaBJDXOIJCkxhkEktS4gYMgyZIk/57kM932siTbk+zplkv7+m5KsjfJ3Ukumo3CJUnDcSxnBG8DdvdtXwnsqKrVwI5umyRrgA3AecA64OokS4ZTriRp2AYKgiQrgNcCH+5rXg9s6da3ABf3tV9fVQ9X1T3AXmDtUKqVJA3doGcEfwz8NvCDvrazqup+gG55Zte+HNjX129/1/Y4SS5PMpZkbHx8/FjrliQNybRBkOR1wMGqumPAMTNBWz2hoeqaqhqtqtGRkZEBh5YkDdtJA/S5APj5JK8BTgWeluQTwANJzq6q+5OcDRzs+u8HVvYdvwI4MMyiJUnDM+0ZQVVtqqoVVbWK3kXgf6mqXwW2ARu7bhuBG7r1bcCGJKckORdYDdw29MolSUMxyBnBZN4LbE1yGXAfcAlAVe1KshW4C3gEuKKqjsy4UknSrEjVE6bv59zo6GiNjY3NdxmLUhIWwr+xNCgfs7MjyR1VNTrRPj9ZLEmNMwgkqXEGgSQ1ziCQpMYZBJLUOINAkhpnEEhS4wwCSWqcQSBJjTMIJKlxBoEkNc4gkKTGGQSS1DiDQJIaZxBIUuMMAklqnEEgSY0zCCSpcQaBJDXOIJCkxhkEktQ4g0CSGmcQSFLjDAJJapxBIEmNMwgkqXEGgSQ1ziCQpMYZBJLUOINAkhpnEEhS4wwCSWrctEGQ5NQktyX5jyS7klzVtS9Lsj3Jnm65tO+YTUn2Jrk7yUWz+QNIkmZmkDOCh4FXVtXzgPOBdUleDFwJ7Kiq1cCObpska4ANwHnAOuDqJEtmoXZJ0hBMGwTV8z/d5sndVwHrgS1d+xbg4m59PXB9VT1cVfcAe4G1wyxakjQ8A10jSLIkyZ3AQWB7Vd0KnFVV9wN0yzO77suBfX2H7+/aJEkL0EBBUFVHqup8YAWwNslzpuieiYZ4Qqfk8iRjScbGx8cHKlaSNHzH9K6hqnoQuJHe3P8DSc4G6JYHu277gZV9h60ADkww1jVVNVpVoyMjI8deuSRpKAZ519BIktO79dOAVwFfA7YBG7tuG4EbuvVtwIYkpyQ5F1gN3DbkuiVJQ3LSAH3OBrZ07/z5IWBrVX0myS3A1iSXAfcBlwBU1a4kW4G7gEeAK6rqyOyUL0maqWmDoKq+DDx/gvZvARdOcsxmYPOMq5MkzTo/WSxJjTMIJKlxBoEkNc4gOIEsW7aMJMf0BRzzMcuWLZvnn1TSXBrkXUNaIA4fPkzVEz6bN3SPBog0U8uWLePw4cPHfNyxPAaXLl3KoUOHjvl76DEGgaRZMxcvXnzhMnNODUlS4wwCSWqcQSBJjTMIJKlxBoEkNc4gkKTGGQSS1DiDQJIaZxBIUuMMAklqnEEgSY0zCCSpcQaBJDXOIJCkxhkEktQ4g0CSGmcQSFLjDAJJapxBIEmNMwgkqXEGgSQ1ziCQpMYZBJLUOINAkhpnEEhS4wwCSWrctEGQZGWSzyfZnWRXkrd17cuSbE+yp1su7TtmU5K9Se5OctFs/gCSpJkZ5IzgEeDtVfUTwIuBK5KsAa4EdlTVamBHt023bwNwHrAOuDrJktkoXpI0c9MGQVXdX1Vf6ta/DewGlgPrgS1dty3Axd36euD6qnq4qu4B9gJrh1y3JGlIjukaQZJVwPOBW4Gzqup+6IUFcGbXbTmwr++w/V2bJGkBGjgIkjwF+BvgN6vqoam6TtBWE4x3eZKxJGPj4+ODliFJGrKBgiDJyfRC4JNV9bdd8wNJzu72nw0c7Nr3Ayv7Dl8BHDh6zKq6pqpGq2p0ZGTkeOuXJM3QIO8aCvARYHdV/VHfrm3Axm59I3BDX/uGJKckORdYDdw2vJIlScN00gB9LgDeAHwlyZ1d2zuB9wJbk1wG3AdcAlBVu5JsBe6i946jK6rqyLALlyQNx7RBUFVfZOJ5f4ALJzlmM7B5BnVJkuaInyyWpMYZBJLUOINAkhpnEEhS4wZ515AWkN67eSVpeAyCE0zVEz6kPXSGjdQWp4YkqXGeEUiaVZ5hLnwGgaRZNdvTmQbNzDk1JEmNMwgkqXEGgSQ1ziCQpMYZBJLUOINAkhpnEEhS4wwCSWqcQSBJjTMIJKlxBoEkNc4gkKTGGQSS1DiDQJIaZxBIUuO8H8EJZi7+9vrSpUtn/XtIWjgMghPI8dzgI8mc3OdY0onLqSFJapxnBJJm1WxPZzqVOXMGgaRZ43TmicGpIUlqnEEgSY0zCCSpcdMGQZKPJjmY5Kt9bcuSbE+yp1su7du3KcneJHcnuWi2CpckDccgZwQfB9Yd1XYlsKOqVgM7um2SrAE2AOd1x1ydZMnQqpUkDd20QVBVNwGHjmpeD2zp1rcAF/e1X19VD1fVPcBeYO1wSpUkzYbjvUZwVlXdD9Atz+zalwP7+vrt79okSQvUsC8WT/TJkQnfEJzk8iRjScbGx8eHXIYkaVDHGwQPJDkboFse7Nr3Ayv7+q0ADkw0QFVdU1WjVTU6MjJynGVIkmbqeINgG7CxW98I3NDXviHJKUnOBVYDt82sREnSbJr2T0wkuQ54OXBGkv3Au4D3AluTXAbcB1wCUFW7kmwF7gIeAa6oqiOzVLskaQimDYKqunSSXRdO0n8zsHkmRUmS5o6fLJakxhkEktQ4g0CSGmcQSFLjDAJJapxBIEmNMwgkqXEGgSQ1ziCQpMYZBJLUOINAkhpnEEhS4wwCSWqcQSBJjTMIJKlxBoEkNc4gkKTGGQSS1DiDQJIaZxBIUuMMAklqnEEgSY0zCCSpcQaBJDXOIJCkxp003wVo5pIc1/6qmo1ypGn5mF1YDIJFwP8cOtH4mF1YnBqSpMYZBJLUOINAkhpnEEhS4wwCSWqcQSBJjTMIJKlxBoEkNS4L4YMdScaBe+e7jkXqDOCb812EdAx8zM6OZ1XVyEQ7FkQQaPYkGauq0fmuQxqUj9m559SQJDXOIJCkxhkEi981812AdIx8zM4xrxFIUuM8I5CkxhkEi1SSdUnuTrI3yZXzXY80lSQfTXIwyVfnu5YWGQSLUJIlwJ8CrwbWAJcmWTO/VUlT+jiwbr6LaJVBsDitBfZW1der6nvA9cD6ea5JmlRV3QQcmu86WmUQLE7LgX192/u7Nkl6AoNgcZrozt++PUzShAyCxWk/sLJvewVwYJ5qkbTAGQSL0+3A6iTnJnkSsAHYNs81SVqgDIJFqKoeAX4D+CywG9haVbvmtyppckmuA24BfjzJ/iSXzXdNLfGTxZLUOM8IJKlxBoEkNc4gkKTGGQSS1DiDQJIaZxBIUuMMAklqnEEgSY37f7DB48Il2VNJAAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "df[\"Words per review\"] = df[\"text\"].str.split().apply(len)\n",
    "df.boxplot(\"Words per review\", by=\"label\", grid=False, showfliers=False,\n",
    "           color=\"black\")\n",
    "plt.suptitle(\"\")\n",
    "plt.xlabel(\"\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 0 is negative\n",
    "# 1 is positive\n",
    "df[df.text.str.len() < 200]\n",
    "imdb.reset_format()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "634e9b6f215a4ea79451a80f347b292d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/29.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "00478de7b838443797287a8ec76a6550",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/411 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "29e1c528dca34b4695c5d37659b3703c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/208k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dad938ba97e948c691301dda1a1929d8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/426k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9bddae182d4f498ea2a10943140965f7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0a40ce36ef2b4b0fb214969465736a55",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8dd96e9ada88451eb79c6031f6bc1e98",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['text', 'label', 'input_ids', 'attention_mask'],\n",
       "        num_rows: 1600\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['text', 'label', 'input_ids', 'attention_mask'],\n",
       "        num_rows: 400\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['text', 'label', 'input_ids', 'attention_mask'],\n",
       "        num_rows: 400\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import AutoTokenizer\n",
    "\n",
    "checkpoint = \"distilbert-base-cased\"\n",
    "#checkpoint = \"bert-base-cased\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(checkpoint)\n",
    "\n",
    "def tokenize_function(batch):\n",
    "    return tokenizer(batch[\"text\"], padding=True, truncation=True)\n",
    "\n",
    "imdb_encoded = imdb.map(tokenize_function, batched=True, batch_size=None)\n",
    "imdb_encoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'text': 'Despite positive reviews and screenings at the international festivals, this movie is not for everyone.<br /><br />The story is very similar to other movies, in which a teenage girl from the family of immigrants needs to overcome many common personal problems of her age, and also to struggle against the pressure of ethnic traditions in her family. She does that by choosing some kind of sport, and with the help of a local boy, that for some reason falls in love with her, she confronts her problems and wins.<br /><br />In Girlfight it\\'s boxing, in Bend it like Beckham it\\'s soccer, and now it\\'s Kung Fu.<br /><br />But Fighter is much inferior product than these two, it was simply embarrassing to watch it. Semra Turan, the \"actress\" that playing the role of a teenage girl, maybe can do a lot of things, but one thing she can\\'t do is to act. Her presence on the screen is anemic and clumsy, the dramatic situations, in which she tries to show some emotions, are dreadful, her body and facial language are of amateur actress, badly instructed by the director. The rest of the cast is a little better, but they just cannot save this cliché movie with stereotypical characters and shallow plot. Besides a few relatively good moments this movie has nothing new or interesting to offer.<br /><br />Even the kung fu fighting is not a reason to watch this, it\\'s just so boring. The slow motion was really unnecessary, the choreography was basic and lacked the inspiration, and most of the kung fu scenes are just training or standing in all kind of kung fu positions, not actually fighting. Not to mention how ridiculous it looks when a small and skinny girl fights big and muscular boys, and knocks them off their feet. <br /><br />The only reason this movie has been noticed at all is because it\\'s European. It\\'s very easy to publicize this movie - A first martial arts film from Denmark, but don\\'t be fooled, it\\'s not. It\\'s just a drama about stupid teenage girl and her problems, which are, by the way, not really convincing.<br /><br />Bad movie with embarrassing lines, acting and story.', 'label': 0, 'input_ids': [101, 2711, 3112, 3761, 1105, 11954, 1116, 1120, 1103, 1835, 7731, 117, 1142, 2523, 1110, 1136, 1111, 2490, 119, 133, 9304, 120, 135, 133, 9304, 120, 135, 1109, 1642, 1110, 1304, 1861, 1106, 1168, 5558, 117, 1107, 1134, 170, 11009, 1873, 1121, 1103, 1266, 1104, 7162, 2993, 1106, 9414, 1242, 1887, 2357, 2645, 1104, 1123, 1425, 117, 1105, 1145, 1106, 5637, 1222, 1103, 2997, 1104, 5237, 7181, 1107, 1123, 1266, 119, 1153, 1674, 1115, 1118, 11027, 1199, 1912, 1104, 4799, 117, 1105, 1114, 1103, 1494, 1104, 170, 1469, 2298, 117, 1115, 1111, 1199, 2255, 4887, 1107, 1567, 1114, 1123, 117, 1131, 18975, 1123, 2645, 1105, 4646, 119, 133, 9304, 120, 135, 133, 9304, 120, 135, 1130, 4537, 22805, 1122, 112, 188, 10568, 117, 1107, 15913, 1122, 1176, 10429, 2522, 1122, 112, 188, 5862, 117, 1105, 1208, 1122, 112, 188, 24120, 14763, 119, 133, 9304, 120, 135, 133, 9304, 120, 135, 1252, 7388, 1110, 1277, 15543, 3317, 1190, 1292, 1160, 117, 1122, 1108, 2566, 17810, 1106, 2824, 1122, 119, 22087, 1306, 1611, 17037, 4047, 117, 1103, 107, 3647, 107, 1115, 1773, 1103, 1648, 1104, 170, 11009, 1873, 117, 2654, 1169, 1202, 170, 1974, 1104, 1614, 117, 1133, 1141, 1645, 1131, 1169, 112, 189, 1202, 1110, 1106, 2496, 119, 1430, 2915, 1113, 1103, 3251, 1110, 1126, 5521, 1596, 1105, 26928, 117, 1103, 7271, 7832, 117, 1107, 1134, 1131, 4642, 1106, 1437, 1199, 6288, 117, 1132, 25671, 117, 1123, 1404, 1105, 14078, 1846, 1132, 1104, 6135, 3647, 117, 6118, 10154, 1118, 1103, 1900, 119, 1109, 1832, 1104, 1103, 2641, 1110, 170, 1376, 1618, 117, 1133, 1152, 1198, 2834, 3277, 1142, 172, 16879, 2744, 2523, 1114, 17000, 2340, 15328, 2650, 1105, 8327, 4928, 119, 4981, 170, 1374, 3860, 1363, 4899, 1142, 2523, 1144, 1720, 1207, 1137, 5426, 1106, 2906, 119, 133, 9304, 120, 135, 133, 9304, 120, 135, 2431, 1103, 180, 4380, 175, 1358, 2935, 1110, 1136, 170, 2255, 1106, 2824, 1142, 117, 1122, 112, 188, 1198, 1177, 12533, 119, 1109, 3345, 4018, 1108, 1541, 14924, 117, 1103, 22543, 1108, 3501, 1105, 10778, 1103, 7670, 117, 1105, 1211, 1104, 1103, 180, 4380, 175, 1358, 4429, 1132, 1198, 2013, 1137, 2288, 1107, 1155, 1912, 1104, 180, 4380, 175, 1358, 3638, 117, 1136, 2140, 2935, 119, 1753, 1106, 4734, 1293, 9944, 1122, 2736, 1165, 170, 1353, 1105, 19244, 1873, 9718, 1992, 1105, 14310, 3287, 117, 1105, 24895, 1172, 1228, 1147, 1623, 119, 133, 9304, 120, 135, 133, 9304, 120, 135, 1109, 1178, 2255, 1142, 2523, 1144, 1151, 3535, 1120, 1155, 1110, 1272, 1122, 112, 188, 1735, 119, 1135, 112, 188, 1304, 3123, 1106, 1470, 3708, 1142, 2523, 118, 138, 1148, 8317, 3959, 1273, 1121, 5140, 117, 1133, 1274, 112, 189, 1129, 8906, 1174, 117, 1122, 112, 188, 1136, 119, 1135, 112, 188, 1198, 170, 3362, 1164, 4736, 11009, 1873, 1105, 1123, 2645, 117, 1134, 1132, 117, 1118, 1103, 1236, 117, 1136, 1541, 13870, 119, 133, 9304, 120, 135, 133, 9304, 120, 135, 6304, 2523, 1114, 17810, 2442, 117, 3176, 1105, 1642, 119, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]}\n"
     ]
    }
   ],
   "source": [
    "print(imdb_encoded['train'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a8cfe701cf8b40e4acbc9a48197b03b9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/251M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at distilbert-base-cased were not used when initializing DistilBertForSequenceClassification: ['vocab_transform.bias', 'vocab_projector.bias', 'vocab_projector.weight', 'vocab_transform.weight', 'vocab_layer_norm.bias', 'vocab_layer_norm.weight']\n",
      "- This IS expected if you are initializing DistilBertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing DistilBertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-cased and are newly initialized: ['pre_classifier.bias', 'classifier.weight', 'classifier.bias', 'pre_classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import AutoModelForSequenceClassification\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "num_labels = 2\n",
    "model = (AutoModelForSequenceClassification\n",
    "         .from_pretrained(checkpoint, num_labels=num_labels)\n",
    "         .to(device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6aa761cc99a74939a5ba0b9df18f51a4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d8eda1ae8482462795516a36ee730e10",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "55124902297f480d829419fe9b55a9df",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['text', 'label', 'input_ids', 'attention_mask'],\n",
       "        num_rows: 50\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['text', 'label', 'input_ids', 'attention_mask'],\n",
       "        num_rows: 10\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['text', 'label', 'input_ids', 'attention_mask'],\n",
       "        num_rows: 10\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from datasets import DatasetDict\n",
    "\n",
    "tiny_imdb = DatasetDict()\n",
    "tiny_imdb['train'] = imdb['train'].shuffle(seed=1).select(range(50))\n",
    "tiny_imdb['validation'] = imdb['validation'].shuffle(seed=1).select(range(10))\n",
    "tiny_imdb['test'] = imdb['test'].shuffle(seed=1).select(range(10))\n",
    "\n",
    "tiny_imdb_encoded = tiny_imdb.map(tokenize_function, batched=True, batch_size=None)\n",
    "tiny_imdb_encoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TrainingArguments(\n",
       "_n_gpu=0,\n",
       "adafactor=False,\n",
       "adam_beta1=0.9,\n",
       "adam_beta2=0.999,\n",
       "adam_epsilon=1e-08,\n",
       "bf16=False,\n",
       "bf16_full_eval=False,\n",
       "data_seed=None,\n",
       "dataloader_drop_last=False,\n",
       "dataloader_num_workers=0,\n",
       "dataloader_pin_memory=True,\n",
       "ddp_bucket_cap_mb=None,\n",
       "ddp_find_unused_parameters=None,\n",
       "debug=[],\n",
       "deepspeed=None,\n",
       "disable_tqdm=False,\n",
       "do_eval=True,\n",
       "do_predict=False,\n",
       "do_train=False,\n",
       "eval_accumulation_steps=None,\n",
       "eval_delay=0,\n",
       "eval_steps=None,\n",
       "evaluation_strategy=IntervalStrategy.EPOCH,\n",
       "fp16=False,\n",
       "fp16_backend=auto,\n",
       "fp16_full_eval=False,\n",
       "fp16_opt_level=O1,\n",
       "gradient_accumulation_steps=1,\n",
       "gradient_checkpointing=False,\n",
       "greater_is_better=None,\n",
       "group_by_length=False,\n",
       "half_precision_backend=auto,\n",
       "hub_model_id=None,\n",
       "hub_strategy=HubStrategy.EVERY_SAVE,\n",
       "hub_token=<HUB_TOKEN>,\n",
       "ignore_data_skip=False,\n",
       "label_names=None,\n",
       "label_smoothing_factor=0.0,\n",
       "learning_rate=2e-05,\n",
       "length_column_name=length,\n",
       "load_best_model_at_end=False,\n",
       "local_rank=-1,\n",
       "log_level=40,\n",
       "log_level_replica=-1,\n",
       "log_on_each_node=True,\n",
       "logging_dir=distilbert-base-cased-finetuned-tiny-imdb/runs/Oct11_22-42-06_reneessupermbp.wireless-1x.unc.edu,\n",
       "logging_first_step=False,\n",
       "logging_nan_inf_filter=True,\n",
       "logging_steps=6,\n",
       "logging_strategy=IntervalStrategy.STEPS,\n",
       "lr_scheduler_type=SchedulerType.LINEAR,\n",
       "max_grad_norm=1.0,\n",
       "max_steps=-1,\n",
       "metric_for_best_model=None,\n",
       "mp_parameters=,\n",
       "no_cuda=False,\n",
       "num_train_epochs=2,\n",
       "optim=OptimizerNames.ADAMW_TORCH,\n",
       "output_dir=distilbert-base-cased-finetuned-tiny-imdb,\n",
       "overwrite_output_dir=False,\n",
       "past_index=-1,\n",
       "per_device_eval_batch_size=8,\n",
       "per_device_train_batch_size=8,\n",
       "prediction_loss_only=False,\n",
       "push_to_hub=False,\n",
       "push_to_hub_model_id=None,\n",
       "push_to_hub_organization=None,\n",
       "push_to_hub_token=<PUSH_TO_HUB_TOKEN>,\n",
       "remove_unused_columns=True,\n",
       "report_to=['mlflow', 'tensorboard', 'wandb'],\n",
       "resume_from_checkpoint=None,\n",
       "run_name=distilbert-base-cased-finetuned-tiny-imdb,\n",
       "save_on_each_node=False,\n",
       "save_steps=500,\n",
       "save_strategy=IntervalStrategy.STEPS,\n",
       "save_total_limit=None,\n",
       "seed=42,\n",
       "sharded_ddp=[],\n",
       "skip_memory_metrics=True,\n",
       "tf32=None,\n",
       "tpu_metrics_debug=False,\n",
       "tpu_num_cores=None,\n",
       "use_legacy_prediction_loop=False,\n",
       "warmup_ratio=0.0,\n",
       "warmup_steps=0,\n",
       "weight_decay=0.01,\n",
       "xpu_backend=None,\n",
       ")"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import Trainer, TrainingArguments\n",
    "\n",
    "batch_size = 8\n",
    "logging_steps = len(tiny_imdb_encoded[\"train\"]) // batch_size\n",
    "model_name = f\"{checkpoint}-finetuned-tiny-imdb\"\n",
    "training_args = TrainingArguments(output_dir=model_name,\n",
    "                                  num_train_epochs=2,\n",
    "                                  learning_rate=2e-5,\n",
    "                                  per_device_train_batch_size=batch_size,\n",
    "                                  per_device_eval_batch_size=batch_size,\n",
    "                                  weight_decay=0.01,\n",
    "                                  evaluation_strategy=\"epoch\",\n",
    "                                  disable_tqdm=False,\n",
    "                                  logging_steps=logging_steps,\n",
    "                                  log_level=\"error\",\n",
    "                                  optim='adamw_torch'\n",
    "                                  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Logging into wandb.ai. (Learn how to deploy a W&B server locally: https://wandb.me/wandb-server)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: You can find your API key in your browser here: https://wandb.ai/authorize\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Paste an API key from your profile and hit enter, or press ctrl+c to quit:\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /Users/karen/.netrc\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.13.4 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.13.1"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/Users/karen/Desktop/inls690/untitled folder/wandb/run-20221011_230237-2thh0ae8</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/isrene/huggingface/runs/2thh0ae8\" target=\"_blank\">distilbert-base-cased-finetuned-tiny-imdb</a></strong> to <a href=\"https://wandb.ai/isrene/huggingface\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bfc41e7c23844d31a847cdc0da48217c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/14 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.6966, 'learning_rate': 1.1428571428571429e-05, 'epoch': 0.86}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d1bcdcd0308243c18ea067e4799aeccc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.7044218182563782, 'eval_runtime': 15.9444, 'eval_samples_per_second': 0.627, 'eval_steps_per_second': 0.125, 'epoch': 1.0}\n",
      "{'loss': 0.6755, 'learning_rate': 2.8571428571428573e-06, 'epoch': 1.71}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fba1529d2e6145539579620dda88010f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.7186421751976013, 'eval_runtime': 6.0757, 'eval_samples_per_second': 1.646, 'eval_steps_per_second': 0.329, 'epoch': 2.0}\n",
      "{'train_runtime': 486.8032, 'train_samples_per_second': 0.205, 'train_steps_per_second': 0.029, 'train_loss': 0.6790674754551479, 'epoch': 2.0}\n"
     ]
    }
   ],
   "source": [
    "from transformers import Trainer\n",
    "\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "trainer = Trainer(model=model, \n",
    "                  args=training_args, \n",
    "                  train_dataset=tiny_imdb_encoded[\"train\"],\n",
    "                  eval_dataset=tiny_imdb_encoded[\"validation\"],\n",
    "                  tokenizer=tokenizer)\n",
    "trainer.train();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9eb409b37f764a9e87615f07427c063c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "PredictionOutput(predictions=array([[ 0.08594816, -0.16521277],\n",
       "       [ 0.05818872, -0.12268246],\n",
       "       [ 0.07783253, -0.15271339],\n",
       "       [ 0.07970534, -0.1489256 ],\n",
       "       [ 0.09269353, -0.13750648],\n",
       "       [ 0.10625673, -0.19395885],\n",
       "       [ 0.10101943, -0.16549015],\n",
       "       [ 0.10583945, -0.16423708],\n",
       "       [ 0.08208867, -0.13910128],\n",
       "       [ 0.06503416, -0.13956109]], dtype=float32), label_ids=array([0, 0, 1, 1, 0, 0, 0, 0, 1, 0]), metrics={'test_loss': 0.6492040753364563, 'test_runtime': 6.4475, 'test_samples_per_second': 1.551, 'test_steps_per_second': 0.31})"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds = trainer.predict(tiny_imdb_encoded['test'])\n",
    "preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.5 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "eba38789ab565d76f074e8fa97ecc7da63eb4a5e1ba28cc348f16f5285783ca7"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
